{
    "model_name": "mixtral:8x7b",
    "max_tokens": 29000,        
    "temperature": 0.1,
    "chunk_overlap":200,                 
    "chunk_size": 300,
    "tokenizer_model": "tokenization_model/mistralai",
    "max_tokens_check": 300
}

